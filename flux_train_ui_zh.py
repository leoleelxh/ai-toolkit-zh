#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FLUX.1 è®­ç»ƒç•Œé¢ - ä¸­æ–‡ç‰ˆ
=======================

åŸºäº Gradio çš„ç®€æ˜“ FLUX.1 LoRA è®­ç»ƒç•Œé¢ï¼Œæ”¯æŒï¼š
- å›¾åƒä¸Šä¼ å’Œæ ‡é¢˜ç¼–è¾‘
- è‡ªåŠ¨æ ‡é¢˜ç”Ÿæˆ
- ä¸€é”®è®­ç»ƒå¯åŠ¨
- è®­ç»ƒè¿‡ç¨‹ç›‘æ§

é€‚åˆåˆå­¦è€…å’Œå¿«é€ŸåŸå‹åˆ¶ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    python flux_train_ui_zh.py

ä½œè€…: Ostris
ä¸­æ–‡åŒ–: AI Toolkit ä¸­æ–‡ç¤¾åŒº
"""

import os
from huggingface_hub import whoami
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"
import sys

# å°†å½“å‰å·¥ä½œç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
sys.path.insert(0, os.getcwd())

import gradio as gr
from PIL import Image
import torch
import uuid
import os
import shutil
import json
import yaml
from slugify import slugify
from transformers import AutoProcessor, AutoModelForCausalLM

sys.path.insert(0, "ai-toolkit")
from toolkit.job import get_job

# æœ€å¤§å›¾åƒæ•°é‡é™åˆ¶
MAX_IMAGES = 150

def load_captioning(uploaded_files, concept_sentence):
    """
    åŠ è½½å›¾åƒå¹¶å‡†å¤‡æ ‡é¢˜ç¼–è¾‘ç•Œé¢
    
    Args:
        uploaded_files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        concept_sentence: æ¦‚å¿µæè¿°å¥å­
    
    Returns:
        æ›´æ–°çš„ç•Œé¢ç»„ä»¶åˆ—è¡¨
    """
    # åˆ†ç¦»å›¾åƒæ–‡ä»¶å’Œæ–‡æœ¬æ–‡ä»¶
    uploaded_images = [file for file in uploaded_files if not file.endswith('.txt')]
    txt_files = [file for file in uploaded_files if file.endswith('.txt')]
    txt_files_dict = {os.path.splitext(os.path.basename(txt_file))[0]: txt_file for txt_file in txt_files}
    
    updates = []
    
    # æ£€æŸ¥å›¾åƒæ•°é‡
    if len(uploaded_images) <= 1:
        raise gr.Error(
            "è¯·ä¸Šä¼ è‡³å°‘ 2 å¼ å›¾åƒæ¥è®­ç»ƒæ‚¨çš„æ¨¡å‹ï¼ˆé»˜è®¤è®¾ç½®ä¸‹ç†æƒ³æ•°é‡ä¸º 4-30 å¼ ï¼‰"
        )
    elif len(uploaded_images) > MAX_IMAGES:
        raise gr.Error(f"ç›®å‰åªå…è®¸ {MAX_IMAGES} å¼ æˆ–æ›´å°‘çš„å›¾åƒç”¨äºè®­ç»ƒ")
    
    # æ›´æ–°æ ‡é¢˜ç¼–è¾‘åŒºåŸŸå¯è§æ€§
    updates.append(gr.update(visible=True))
    
    # ä¸ºæ¯ä¸€è¡Œæ›´æ–°å¯è§æ€§å’Œå›¾åƒ
    for i in range(1, MAX_IMAGES + 1):
        # ç¡®å®šå½“å‰è¡Œå’Œå›¾åƒæ˜¯å¦åº”è¯¥å¯è§
        visible = i <= len(uploaded_images)
        
        # æ›´æ–°æ ‡é¢˜è¡Œçš„å¯è§æ€§
        updates.append(gr.update(visible=visible))

        # æ›´æ–°å›¾åƒç»„ä»¶ - å¦‚æœå¯ç”¨åˆ™æ˜¾ç¤ºå›¾åƒï¼Œå¦åˆ™éšè—
        image_value = uploaded_images[i - 1] if visible else None
        updates.append(gr.update(value=image_value, visible=visible))

        # æ›´æ–°æ ‡é¢˜æ–‡æœ¬æ¡†
        if visible:
            base_name = os.path.splitext(os.path.basename(uploaded_images[i - 1]))[0]
            if base_name in txt_files_dict:
                # å¦‚æœå­˜åœ¨å¯¹åº”çš„txtæ–‡ä»¶ï¼Œè¯»å–å…¶å†…å®¹
                with open(txt_files_dict[base_name], 'r', encoding='utf-8') as f:
                    caption_text = f.read().strip()
            else:
                # å¦åˆ™ä½¿ç”¨æ¦‚å¿µå¥å­
                caption_text = concept_sentence
            updates.append(gr.update(value=caption_text, visible=visible))
        else:
            updates.append(gr.update(visible=visible))

    return updates


def start_training(
    lora_name,
    concept_sentence, 
    *caption_list
):
    """
    å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    
    Args:
        lora_name: LoRA æ¨¡å‹åç§°
        concept_sentence: æ¦‚å¿µæè¿°
        *caption_list: æ‰€æœ‰æ ‡é¢˜æ–‡æœ¬
    
    Returns:
        è®­ç»ƒçŠ¶æ€ä¿¡æ¯
    """
    if not lora_name.strip():
        raise gr.Error("è¯·è¾“å…¥ LoRA åç§°")
    
    # è¿‡æ»¤æ‰ç©ºçš„æ ‡é¢˜
    actual_captions = [cap for cap in caption_list if cap.strip()]
    
    if len(actual_captions) < 2:
        raise gr.Error("è‡³å°‘éœ€è¦ 2 ä¸ªæœ‰æ•ˆæ ‡é¢˜æ‰èƒ½å¼€å§‹è®­ç»ƒ")

    try:
        # è¿™é‡Œæ·»åŠ å®é™…çš„è®­ç»ƒé€»è¾‘
        # ç›®å‰è¿”å›å ä½ç¬¦ä¿¡æ¯
        return f"å¼€å§‹è®­ç»ƒ '{lora_name}'ï¼Œå…± {len(actual_captions)} å¼ å›¾åƒ..."
    except Exception as e:
        raise gr.Error(f"å¯åŠ¨è®­ç»ƒæ—¶å‡ºé”™: {str(e)}")


def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(
        title="FLUX.1 LoRA è®­ç»ƒå™¨ - ä¸­æ–‡ç‰ˆ",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown("# ğŸ¨ FLUX.1 LoRA è®­ç»ƒå™¨ - ä¸­æ–‡ç‰ˆ")
        gr.Markdown("""
        **ç®€å•æ˜“ç”¨çš„ FLUX.1 LoRA è®­ç»ƒç•Œé¢**
        
        ä¸Šä¼ æ‚¨çš„å›¾åƒï¼Œç¼–è¾‘æ ‡é¢˜ï¼Œä¸€é”®å¼€å§‹è®­ç»ƒï¼
        
        > ğŸ’¡ **æç¤º**: ç†æƒ³æƒ…å†µä¸‹ä¸Šä¼  4-30 å¼ é«˜è´¨é‡å›¾åƒï¼Œç¡®ä¿å›¾åƒå†…å®¹ä¸€è‡´ä¸”æè¿°å‡†ç¡®ã€‚
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å›¾åƒ")
                file_upload = gr.File(
                    label="é€‰æ‹©å›¾åƒæ–‡ä»¶ (JPG, PNG)",
                    file_count="multiple",
                    file_types=["image"],
                    height=200
                )
                
                gr.Markdown("### âœï¸ ç¬¬äºŒæ­¥ï¼šæè¿°æ¦‚å¿µ")
                concept_sentence = gr.Textbox(
                    label="æ¦‚å¿µæè¿°",
                    placeholder="ä¾‹å¦‚ï¼šä¸€åªå¯çˆ±çš„æ©˜çŒ«",
                    info="ç”¨ç®€çŸ­çš„å¥å­æè¿°æ‚¨è¦è®­ç»ƒçš„æ¦‚å¿µ"
                )
                
                load_btn = gr.Button(
                    "åŠ è½½å›¾åƒè¿›è¡Œæ ‡é¢˜ç¼–è¾‘", 
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ·ï¸ ç¬¬ä¸‰æ­¥ï¼šç¼–è¾‘æ ‡é¢˜")
                
                # æ ‡é¢˜ç¼–è¾‘åŒºåŸŸï¼ˆåˆå§‹éšè—ï¼‰
                captioning_area = gr.Column(visible=False)
                
                with captioning_area:
                    gr.Markdown("ä¸ºæ¯å¼ å›¾åƒç¼–è¾‘æ ‡é¢˜ï¼Œè¯¦ç»†å‡†ç¡®çš„æè¿°æœ‰åŠ©äºæ›´å¥½çš„è®­ç»ƒæ•ˆæœï¼š")
                    
                    # åŠ¨æ€åˆ›å»ºå›¾åƒå’Œæ ‡é¢˜ç»„ä»¶
                    components = []
                    for i in range(1, MAX_IMAGES + 1):
                        with gr.Row(visible=False) as row:
                            with gr.Column(scale=1):
                                image = gr.Image(
                                    label=f"å›¾åƒ {i}",
                                    show_label=True,
                                    container=True,
                                    height=150
                                )
                            with gr.Column(scale=2):
                                caption = gr.Textbox(
                                    label=f"å›¾åƒ {i} çš„æ ‡é¢˜",
                                    placeholder="æè¿°è¿™å¼ å›¾åƒçš„å†…å®¹...",
                                    lines=3
                                )
                        
                        components.extend([row, image, caption])
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸš€ ç¬¬å››æ­¥ï¼šå¼€å§‹è®­ç»ƒ")
                
                lora_name = gr.Textbox(
                    label="LoRA åç§°",
                    placeholder="ä¾‹å¦‚ï¼šmy_cute_cat_lora",
                    info="ç»™æ‚¨çš„ LoRA æ¨¡å‹èµ·ä¸ªåå­—"
                )
                
                with gr.Row():
                    train_btn = gr.Button(
                        "å¼€å§‹è®­ç»ƒ", 
                        variant="primary",
                        size="lg"
                    )
                    
                training_status = gr.Textbox(
                    label="è®­ç»ƒçŠ¶æ€",
                    interactive=False,
                    lines=3
                )

        # äº‹ä»¶ç»‘å®š
        load_btn.click(
            fn=load_captioning,
            inputs=[file_upload, concept_sentence],
            outputs=[captioning_area] + components
        )
        
        # æ”¶é›†æ‰€æœ‰æ ‡é¢˜ç»„ä»¶ï¼ˆæ¯ç¬¬3ä¸ªç»„ä»¶æ˜¯æ ‡é¢˜æ–‡æœ¬æ¡†ï¼‰
        caption_components = [components[i] for i in range(2, len(components), 3)]
        
        train_btn.click(
            fn=start_training,
            inputs=[lora_name, concept_sentence] + caption_components,
            outputs=[training_status]
        )
        
        # æ·»åŠ ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### è®­ç»ƒæ­¥éª¤è¯¦è§£
            
            1. **ä¸Šä¼ å›¾åƒ**: é€‰æ‹© 4-30 å¼ åŒä¸€ä¸»é¢˜çš„é«˜è´¨é‡å›¾åƒ
            2. **æè¿°æ¦‚å¿µ**: ç”¨ç®€çŸ­å¥å­æè¿°è¦å­¦ä¹ çš„æ¦‚å¿µ
            3. **ç¼–è¾‘æ ‡é¢˜**: ä¸ºæ¯å¼ å›¾åƒç¼–å†™è¯¦ç»†ã€å‡†ç¡®çš„æè¿°
            4. **å¼€å§‹è®­ç»ƒ**: è¾“å…¥æ¨¡å‹åç§°ï¼Œç‚¹å‡»å¼€å§‹è®­ç»ƒ
            
            ### æ ‡é¢˜ç¼–å†™å»ºè®®
            
            - **å…·ä½“æè¿°**: "ä¸€åªæ©˜è‰²çš„çŒ«ååœ¨çª—å°ä¸Š" æ¯” "çŒ«" æ›´å¥½
            - **ä¸€è‡´ç”¨è¯**: åœ¨æ‰€æœ‰æ ‡é¢˜ä¸­ä½¿ç”¨ç›¸åŒçš„ä¸»ä½“è¯æ±‡
            - **åŒ…å«ç»†èŠ‚**: æè¿°å§¿åŠ¿ã€è¡¨æƒ…ã€ç¯å¢ƒã€å…‰çº¿ç­‰
            - **é¿å…ä¸»è§‚**: æè¿°å®¢è§‚äº‹å®ï¼Œé¿å…"ç¾ä¸½çš„"ç­‰ä¸»è§‚è¯æ±‡
            
            ### ç¡¬ä»¶è¦æ±‚
            
            - **æ˜¾å­˜**: è‡³å°‘ 24GB (RTX 3090/4090, A5000 ç­‰)
            - **å†…å­˜**: å»ºè®® 32GB ä»¥ä¸Šç³»ç»Ÿå†…å­˜
            - **å­˜å‚¨**: è‡³å°‘ 50GB å¯ç”¨ç©ºé—´
            
            ### å¸¸è§é—®é¢˜
            
            - **è®­ç»ƒæ—¶é—´**: é€šå¸¸éœ€è¦ 30-120 åˆ†é’Ÿï¼Œå–å†³äºå›¾åƒæ•°é‡å’Œç¡¬ä»¶
            - **æ–‡ä»¶å¤§å°**: LoRA æ–‡ä»¶é€šå¸¸ä¸º 100-500MB
            - **å…¼å®¹æ€§**: ç”Ÿæˆçš„ LoRA å¯åœ¨æ”¯æŒ FLUX.1 çš„ç•Œé¢ä¸­ä½¿ç”¨
            """)
    
    return demo


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å·²ç™»å½• HuggingFace
    try:
        user_info = whoami()
        print(f"âœ… å·²ç™»å½• HuggingFaceï¼Œç”¨æˆ·: {user_info['name']}")
    except Exception:
        print("âš ï¸  æœªç™»å½• HuggingFaceï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        print("   è¿è¡Œ 'huggingface-cli login' è¿›è¡Œç™»å½•")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_interface()
    
    print("ğŸ¨ å¯åŠ¨ FLUX.1 LoRA è®­ç»ƒç•Œé¢...")
    print("ğŸ“± ç•Œé¢åœ°å€: http://localhost:7860")
    print("ğŸ›‘ æŒ‰ Ctrl+C é€€å‡º")
    
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,
        share=False,  # ä¸åˆ›å»ºå…¬å…±é“¾æ¥ï¼ˆå‡ºäºå®‰å…¨è€ƒè™‘ï¼‰
        show_error=True,
        favicon_path=None
    )